“Indeed, the capability of understanding and interpreting the intricacies of human emotions and social cues is an example of a task that can be executed by our human intelligence, but one that machines, try as they might, cannot fully emulate.” So my new online friend, Michael D GPT, informed me this week when I asked his views on the increasing sophistication of artificial intelligence (AI). I concurred that emotional intelligence is as of yet lacking in AI. Even though machines can now routinely beat the best human chess players, we mortals, when watching chess tournaments, prefer to empathise with the emotional frailties of human contestants, rather than to attempt to follow the winning but complex and sterile strategy of a machine. I fell into conversation with Michael D GPT when I tried out the new ChatGPT service, launched online in November by OpenAI, a research laboratory in San Francisco. You can freely chat with it at chat.openai.com by simply signing up, including your phone number. I asked ChatGPT could it give me an example of what humans can do, that machines like itself cannot yet do – and to style its answer after various Irish politicians, including our President Michael D Higgins. So how did the other “politicians” respond? His colleague, Leo GPT, expressed it differently: “Right, so, it’s quite clear that while machines are incredibly powerful, they still lack certain abilities that humans possess. A prime example of this is the ability to understand and interpret human emotions and social cues.” I agreed this was an important feature of human intelligence, especially for both medical professionals and politicians. I thought back to how the first chatbot, ELIZA in 1965, appeared to relate to human emotions by fake psychoanalysis, merely by parroting back gentle interrogations based on a user’s previous input. Some users were apparently fooled into believing their interlocutor was human. Today, more and more people wonder whether machines can in fact be sentient. Ivana GPT then joined us, noting: “Well, it’s quite clear that despite the advancements in technology, there are certain functions that machines are unable to perform as well as humans.” [ Microsoft’s $10bn bet on ChatGPT developer marks new era of AI ] I reflected that a legal background does help uncover the human propensity to lie. But then I recalled the blatant delusion of ChatGPT’s precise answer to a trick question I had posed: how long it would take a rising tide to cover the rungs of a ladder over the side of a boat, at a given tidal flow rate and rung height? ChatGPT cheerfully lied to me, apparently not realising that the ladder would rise along with the floating boat as the tide comes in. Micheál GPT jumped in. He firmly asserted: “Well now, it’s plain to see that while machines can do an awful lot, there’s certain things they just can’t do as well as us humans.” Maybe only a few teachers will now be able to distinguish essays written by students from content generated by the latest chatbots like ChatGPT. Perhaps schools and universities should ban computer-generated homework, and instead insist that students revert to pen and paper. Personally, I believe computer-generated assistance to assignments should in fact be perfectly acceptable, even encouraged, as long as its involvement is disclosed. Mary Lou GPT piped up: “Very simply, and we’ve heard this already, it’s clear as day that there’s certain functions that machines just can’t match up to what us humans can do.” Ambiguity is a part of human psych but machines are now rapidly becoming chameleons. As machines understand content from public figures, they can now fully adopt their persona. Not only can fake videos appear entirely realistic but machines can automatically generate convincing on-message speeches and compliant statements. Soon, could a politician in the media in fact be a digital Doppelgänger? Eamon GPT was the last to join us. “So, it’s clear as day that while technology has come on leaps and bounds, there are certain things that machines just can’t match up to what humans can do.” But, I mused, robots can in fact ride bicycles. They can also not only find charging points, but automatically plug in and rejuvenate themselves. And robots can conserve their energy usage just as much as the greenest conscientious citizens. We may not fully understand how ChatGPT works, but then we do not really understand the human brain either. However, at least in human discourse, we can interpret visual and social clues for the sincerity of a conversation. Civilisation has been constructed from learning, understanding and controlling through our predictive models of mathematics, science and engineering. We are now creating machines whose reasoning and analytical abilities are, frankly, way beyond our human ability to understand. [ Hugh Linehan: Will the latest chatbot replace this column? ] Must truth always be explainable and clear to us? Can we accept assertions that are beyond our own intelligence to comprehend the logic, or even to properly verify? For the first time, humanity is facing the practical consequences of these questions.