For the first time in an aeon, there’s a buzz about BuzzFeed. After the quiz-loving US digital media company revealed on Thursday that it plans to work with ChatGPT creator OpenAI to use artificial intelligence (AI) to create content, its stock leapt 150 per cent. On Friday it held on to those gains and whacked on some more. Human journalists everywhere laughed nervously into the weekend. Was this it? Was this the start of the robot infiltration of the media? Obviously, the answer is no. The robot infiltration of the media actually began more than a decade ago. Since then, the deployment of AI by media companies has steadily increased with advances in AI itself. The “what next?” frets are still justified, of course. BuzzFeed’s enthusiasm about ChatGPT, tool of the moment, reflects a new sense of possibility about the power of AI – or a new sense of doom, if you prefer. One of these days, a robot might even figure out to identify all the squares that contain lamp-posts, and then we’ll all be in trouble. What Jonah Peretti, BuzzFeed co-founder and chief executive, told employees – in a memo apparently not written by a robot – was that they could expect “AI inspired content” to “move from an R&D stage to part of our core business.” The technology will be used to create quizzes, help with brainstorming and personalise content for its audience, but won’t be used to write news stories. “To be clear, we see the breakthroughs in AI opening up a new era of creativity that will allow humans to harness creativity in new ways with endless opportunities and applications for good,” said Peretti. There’s a lot to unpack here – an entire baggage belt’s worth of unpacking. Let’s park the oxymoron of “AI inspired content” for a moment and start with why the share price jumped the way it did. Investors often love it when a company does or says anything that implies an imminent slashing of labour costs, but that’s unlikely to be a factor here. BuzzFeed was already in the process of letting go 12 per cent or about 180 of its employees, the December announcement of which failed to stop its struggling share price from shrinking to new lows. The name-dropping of ChatGPT guaranteed coverage of its next big strategy move. Everyone wants to work with OpenAI. The research laboratory is the Paul Mescal of the chatbot world. Microsoft is pumping $10 billion into the thing. With BuzzFeed’s losses obliging it to scale back its news operations and pull the plug on its UK and Australian newsrooms, the forward-thinking vibes that once surrounded Peretti’s enterprise have all but disappeared. A dash of AI probably isn’t the solution, but it might be better than just wilting into irrelevance. The critical context for a triple-digit share price surge, however, is BuzzFeed’s pre-ChatGPT status as a penny stock – meaning its shares were, before last week, trading for less than $1. This made it inherently more exposed to the whims of irrational buyers and sellers. A headline-grabbing share price gain of the magnitude seen by BuzzFeed more often than not points to volatility, not logic. Alongside Peretti’s comments about AI allowing humans to “harness creativity” – a pretty typical example of the techno-optimist genre – the statement that it won’t use technology to write news stories is intriguing. Why not? It certainly wouldn’t be alone if it did. Often we only hear about this practice when it goes wrong, as it has done for CNET. The news outlet last week paused the use of an internally designed AI engine after it was forced to issue corrections on 41 of the 77 published personal finance articles generated by this tool since November. “AI engines, like humans, make mistakes,” said editor-in-chief Connie Guglielmo, which for a journalist is simultaneously nice and frightening to hear. The case for AI-drafted stories nevertheless remains “compelling” to CNET, and it expects to resume its use of “automated storytelling tools”, with improved transparency next time about how these articles are produced. News agencies, meanwhile, have been quietly getting on with the business of automated story generation for years now. Associated Press began using AI to write corporate earnings stories in 2014 and has since added machine-produced sports reporting into its repertoire. Bloomberg’s news service has also long used automation for content such as corporate results summaries, though its AI tool goes by the name Cyborg, which suggests it is capable of more formidable things. The BuzzFeed wheeze, and the market reaction to it, has inevitably prompted journalists to defensively document all the amazing skills human reporters have that robots don’t, lest their own employers get any ideas. Scepticism, a vital trait for any journalist, doesn’t go hand-in-hand with instinctive belief in technological utopia. News media employees told they will be freed from the burden of “commodity news” will assume that translates as imminent redundancy, or at least the ambition-checking threat of it. Not only are robots cheaper and faster, they are yet to join a union. [ Laura Slattery: Sport-averse Netflix finds itself between Chris Rock and a hard place ] [ Laura Slattery: 2022 was the year when even journalists went on strike ] [ Laura Slattery: End of multiple eras as new brooms arrive in media top jobs ] When I first wrote about news outlets’ nascent fondness for the potential of AI in 2012, I went down this anthropomorphic route. For sure, Marvin the Paranoid Android, created by the human brain of the late writer Douglas Adams, would be a perfect fit for any newsroom, I concluded, but robots would surely be too busy with world domination to bother with the small-fry business of replacing flesh-and-blood journalists. The sadder development to me then was that the still human-controlled news media appeared to be becoming more robotic, with playfulness and originality jettisoned in the name for search engine optimisation. While the journalistic tasks best suited to automation are the drearier ones, the ones nobody wants, the risk is that greater use of automation will serve to proliferate that dreariness, even promote it as a merit. Anyone, human or cyborg, can be boring. But AI will be more efficient in its dullness. Hurrah. In truth, the web already seems a lot stupider than it used to do. The idea that slabs of machine-generated text produced by automated, algorithmic processes will become even more ubiquitous doesn’t feel especially helpful to me. But perhaps this is pure nostalgia. Perhaps our expectations will adjust to the new standards. I’ve seen this episode before. Perhaps, rather than being replaced, we will be assimilated.